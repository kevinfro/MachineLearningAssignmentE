{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11370036,"sourceType":"datasetVersion","datasetId":7117650}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:17.122761Z","iopub.execute_input":"2025-04-11T20:46:17.123076Z","iopub.status.idle":"2025-04-11T20:46:17.137711Z","shell.execute_reply.started":"2025-04-11T20:46:17.123054Z","shell.execute_reply":"2025-04-11T20:46:17.136793Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Introduction\nThis project predicts thyroid cancer recurrence after radioactive iodine (RAI) therapy using supervised and unsupervised machine learning. \n\nFor supervised ML Randomforest and Logistic Regression was used.\nFor unsupervised K-means and Hierarchical Clustering was used.","metadata":{}},{"cell_type":"markdown","source":"## Dataset Overview\n\n- **Source**: Institutional dataset (uploaded manually)\n- **Records**: 383 patients\n- **Features**: 13 attributes\n- **Target variable**: `Recurred` (Yes/No)","metadata":{}},{"cell_type":"markdown","source":"Part 1 – Pre-processing/Exploring the data:","metadata":{}},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv('/kaggle/input/thyroid2/filtered_thyroid_data.csv')\ndf.head()\nprint(df.shape)        # Should return (383, 13)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:17.139589Z","iopub.execute_input":"2025-04-11T20:46:17.139944Z","iopub.status.idle":"2025-04-11T20:46:17.156136Z","shell.execute_reply.started":"2025-04-11T20:46:17.139915Z","shell.execute_reply":"2025-04-11T20:46:17.154491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Shape and basic info\nprint(\"Shape:\", df.shape)\ndf.info()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:17.170886Z","iopub.execute_input":"2025-04-11T20:46:17.171454Z","iopub.status.idle":"2025-04-11T20:46:17.181935Z","shell.execute_reply.started":"2025-04-11T20:46:17.171428Z","shell.execute_reply":"2025-04-11T20:46:17.180882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Encode categorical variables\nlabel_cols = df.select_dtypes(include='object').columns\n\nle = LabelEncoder()\ndf_encoded = df.copy()\nfor col in label_cols:\n    df_encoded[col] = le.fit_transform(df_encoded[col])\n\ndf_encoded.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:17.183586Z","iopub.execute_input":"2025-04-11T20:46:17.183945Z","iopub.status.idle":"2025-04-11T20:46:17.213043Z","shell.execute_reply.started":"2025-04-11T20:46:17.183913Z","shell.execute_reply":"2025-04-11T20:46:17.212306Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Check if encoded properly. Should give int instead of the previous object.\ndf_encoded.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:17.213999Z","iopub.execute_input":"2025-04-11T20:46:17.214338Z","iopub.status.idle":"2025-04-11T20:46:17.225021Z","shell.execute_reply.started":"2025-04-11T20:46:17.214318Z","shell.execute_reply":"2025-04-11T20:46:17.224068Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# Distribution of age\n# https://seaborn.pydata.org/generated/seaborn.histplot.html\nplt.figure(figsize=(8,4))\nsns.histplot(df['Age'], bins=20, kde=True)\nplt.title('Age Distribution')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:17.226024Z","iopub.execute_input":"2025-04-11T20:46:17.226371Z","iopub.status.idle":"2025-04-11T20:46:17.479800Z","shell.execute_reply.started":"2025-04-11T20:46:17.226342Z","shell.execute_reply":"2025-04-11T20:46:17.478959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Recurred class distribution\n# https://seaborn.pydata.org/generated/seaborn.countplot.html\nsns.countplot(x='Recurred', data=df)\nplt.title('Recurred Class Balance')\nplt.show()\nprint(df['Recurred'].value_counts(normalize=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:17.482170Z","iopub.execute_input":"2025-04-11T20:46:17.482431Z","iopub.status.idle":"2025-04-11T20:46:17.618224Z","shell.execute_reply.started":"2025-04-11T20:46:17.482412Z","shell.execute_reply":"2025-04-11T20:46:17.617337Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Gender feature distribution\n# https://seaborn.pydata.org/generated/seaborn.countplot.html\nsns.countplot(x='Gender', data=df)\nplt.title('Gender  Balance')\nplt.show()\nprint(df['Gender'].value_counts(normalize=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:17.619144Z","iopub.execute_input":"2025-04-11T20:46:17.619448Z","iopub.status.idle":"2025-04-11T20:46:17.761392Z","shell.execute_reply.started":"2025-04-11T20:46:17.619428Z","shell.execute_reply":"2025-04-11T20:46:17.760452Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Skewed balance between genders.","metadata":{}},{"cell_type":"code","source":"# Boxplot of Age vs Recurred\n# https://seaborn.pydata.org/generated/seaborn.boxplot.html\nsns.boxplot(x='Recurred', y='Age', data=df)\nplt.title('Age vs Recurred')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:17.762487Z","iopub.execute_input":"2025-04-11T20:46:17.762808Z","iopub.status.idle":"2025-04-11T20:46:17.910750Z","shell.execute_reply.started":"2025-04-11T20:46:17.762781Z","shell.execute_reply":"2025-04-11T20:46:17.909879Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Plot distributions for key categories compared to recurrense\n#Cleaner version by ChatGPT with addition of for loop to iterate through the categories\ncat_cols = ['Gender','Hx Radiothreapy', 'Adenopathy', 'Pathology', 'Focality', 'Risk', 'Stage', 'Response']\nfor col in cat_cols:\n    plt.figure(figsize=(8,4))\n    sns.countplot(x=col, hue='Recurred', data=df)\n    plt.title(f'{col} vs. Recurrence')\n    plt.xticks(rotation=45)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:17.911714Z","iopub.execute_input":"2025-04-11T20:46:17.912049Z","iopub.status.idle":"2025-04-11T20:46:19.294383Z","shell.execute_reply.started":"2025-04-11T20:46:17.912021Z","shell.execute_reply":"2025-04-11T20:46:19.293332Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#As only a small degree of people had done radiotherapy previously\n#Check to see if it has statistic importance to remove it or not.\nfrom scipy.stats import fisher_exact\n\ncontingency_table = pd.crosstab(df['Hx Radiothreapy'], df['Recurred'])\nodds_ratio, p_value = fisher_exact(contingency_table)\nprint(f\"p-value: {p_value:.4f}\")  # Significant if p < 0.05","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:19.295364Z","iopub.execute_input":"2025-04-11T20:46:19.295674Z","iopub.status.idle":"2025-04-11T20:46:19.312458Z","shell.execute_reply.started":"2025-04-11T20:46:19.295646Z","shell.execute_reply":"2025-04-11T20:46:19.311614Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"P < 0.05. Hypothesis is discarded. Hx Radiothreapy is kept.","metadata":{}},{"cell_type":"code","source":"#Codeblock generated with ChatGPT 4-Turbo\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Step 1: Drop target and scale the features\nX = df_encoded.drop(columns=['Recurred'])\ny = df_encoded['Recurred']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Step 2: Apply PCA\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n# Step 3: Create a DataFrame for plotting\npca_df = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])\npca_df['Recurred'] = y\n\n# Step 4: Plot PCA projection with class labels\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='Recurred', palette='Set1')\nplt.title('PCA Projection (2D) Colored by Recurred Class')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.grid(True)\nplt.legend(title='Recurred')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:19.313473Z","iopub.execute_input":"2025-04-11T20:46:19.313787Z","iopub.status.idle":"2025-04-11T20:46:19.575549Z","shell.execute_reply.started":"2025-04-11T20:46:19.313755Z","shell.execute_reply":"2025-04-11T20:46:19.574746Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Part 2: Supervised learning","metadata":{}},{"cell_type":"code","source":"# Target variable\n# https://www.geeksforgeeks.org/random-forest-algorithm-in-machine-learning/\ntarget = 'Recurred'\nX = df_encoded.drop(columns=[target])\ny = df_encoded[target]\n\n# Train-test split (70/30)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\nprint(\"Train size:\", X_train.shape)\nprint(\"Test size:\", X_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:19.576504Z","iopub.execute_input":"2025-04-11T20:46:19.576786Z","iopub.status.idle":"2025-04-11T20:46:19.587800Z","shell.execute_reply.started":"2025-04-11T20:46:19.576747Z","shell.execute_reply":"2025-04-11T20:46:19.586966Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"LogisticRegression","metadata":{}},{"cell_type":"code","source":"#Example modified from https://www.kaggle.com/code/gururajbhase/logistic-regression\nfrom sklearn.linear_model import LogisticRegression\n\n# Baseline model\nlr = LogisticRegression(max_iter=1000)\nlr.fit(X_train, y_train)\ny_pred_lr = lr.predict(X_test)\n\n# Evaluation\nprint(\"Logistic Regression Performance:\")\nprint(classification_report(y_test, y_pred_lr))\n\n# Confusion matrix generated by ChatGPT 4-Turbo\nsns.heatmap(confusion_matrix(y_test, y_pred_lr), annot=True, fmt='d')\nplt.title(\"Confusion Matrix: Logistic Regression\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:19.588767Z","iopub.execute_input":"2025-04-11T20:46:19.589077Z","iopub.status.idle":"2025-04-11T20:46:20.630184Z","shell.execute_reply.started":"2025-04-11T20:46:19.589048Z","shell.execute_reply":"2025-04-11T20:46:20.629284Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Try different C values (regularization)\nfor C in [0.01, 0.1, 1, 10]:\n    model = LogisticRegression(C=C, max_iter=1000)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    print(f\"Logistic Regression with C={C}\")\n    print(classification_report(y_test, preds))\n    print('-'*50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:20.632892Z","iopub.execute_input":"2025-04-11T20:46:20.633137Z","iopub.status.idle":"2025-04-11T20:46:23.281974Z","shell.execute_reply.started":"2025-04-11T20:46:20.633119Z","shell.execute_reply":"2025-04-11T20:46:23.281180Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"RandomForest","metadata":{}},{"cell_type":"code","source":"#Example modified from https://www.kaggle.com/code/dansbecker/exercise-random-forests\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n# Define the model. Set random_state to 42\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train, y_train)\n\n# Predict on validation data (X_test)\ny_pred_rf = rf_model.predict(X_test)\n\n# Evaluation\nprint(\"Random Forest Performance:\")\nprint(classification_report(y_test, y_pred_rf))\n\n# Plot confusion matrix\n# Confusion matrix generated by ChatGPT 4-Turbo\nsns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d')\nplt.title(\"Confusion Matrix: Random Forest\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:23.284819Z","iopub.execute_input":"2025-04-11T20:46:23.285227Z","iopub.status.idle":"2025-04-11T20:46:23.656491Z","shell.execute_reply.started":"2025-04-11T20:46:23.285201Z","shell.execute_reply":"2025-04-11T20:46:23.655480Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Try different n_estimators and max_depth\nfor n in [50, 100, 200]:\n    for d in [None, 5, 10]:\n        rf_model = RandomForestClassifier(n_estimators=n, max_depth=d, random_state=42)\n        rf_model.fit(X_train, y_train)\n        preds = rf_model.predict(X_test)\n        print(f\"Random Forest (n_estimators={n}, max_depth={d})\")\n        print(classification_report(y_test, preds))\n        print('-'*60)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:23.657454Z","iopub.execute_input":"2025-04-11T20:46:23.657808Z","iopub.status.idle":"2025-04-11T20:46:25.308741Z","shell.execute_reply.started":"2025-04-11T20:46:23.657781Z","shell.execute_reply":"2025-04-11T20:46:25.307770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compare training and test accuracy\ntrain_acc = rf.score(X_train, y_train)\ntest_acc = rf.score(X_test, y_test)\n\nprint(f\"Random Forest Training Accuracy: {train_acc:.2f}\")\nprint(f\"Random Forest Test Accuracy: {test_acc:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:25.309668Z","iopub.execute_input":"2025-04-11T20:46:25.309938Z","iopub.status.idle":"2025-04-11T20:46:25.336493Z","shell.execute_reply.started":"2025-04-11T20:46:25.309919Z","shell.execute_reply":"2025-04-11T20:46:25.335559Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Part 3 – Unsupervised learning\nK-Means","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\n\n# Use encoded data without the target column\nX_unsupervised = df_encoded.drop(columns=['Recurred'])\n\n# Cleaned up with ChatGPT 4-Turbo. Instead of a line for getting a score per cluster,\n# For loop used to iterate. \n# Try different k values\nsilhouette_scores = []\n\nfor k in range(2, 10):\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    labels = kmeans.fit_predict(X_unsupervised)\n    score = silhouette_score(X_unsupervised, labels)\n    silhouette_scores.append(score)\n    print(f\"K={k} => Silhouette Score: {score:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:25.337469Z","iopub.execute_input":"2025-04-11T20:46:25.337688Z","iopub.status.idle":"2025-04-11T20:46:25.574046Z","shell.execute_reply.started":"2025-04-11T20:46:25.337670Z","shell.execute_reply":"2025-04-11T20:46:25.573173Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot silhouette scores\nplt.plot(range(2, 10), silhouette_scores, marker='o')\nplt.title(\"K-Means Silhouette Scores\")\nplt.xlabel(\"Number of Clusters (k)\")\nplt.ylabel(\"Silhouette Score\")\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:25.575024Z","iopub.execute_input":"2025-04-11T20:46:25.575382Z","iopub.status.idle":"2025-04-11T20:46:25.759885Z","shell.execute_reply.started":"2025-04-11T20:46:25.575352Z","shell.execute_reply":"2025-04-11T20:46:25.758832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fit KMeans with optimal K. Set here at 2. \nkmeans_final = KMeans(n_clusters=2, random_state=42)\nclusters = kmeans_final.fit_predict(X_unsupervised)\n\n# Visualize with PCA\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_unsupervised)\n\nplt.figure(figsize=(8,5))\nsns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=clusters, palette='Set2')\nplt.title(\"K-Means Clustering (PCA projection)\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T21:01:11.641203Z","iopub.execute_input":"2025-04-11T21:01:11.641650Z","iopub.status.idle":"2025-04-11T21:01:11.904532Z","shell.execute_reply.started":"2025-04-11T21:01:11.641618Z","shell.execute_reply":"2025-04-11T21:01:11.903345Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Hierarchical Clustering","metadata":{}},{"cell_type":"code","source":"# https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\n# Create linkage matrix\nlinked = linkage(X_unsupervised, method='ward')\nfig = plt.figure(figsize=(25, 10))\ndn = dendrogram(linked)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:26.013848Z","iopub.execute_input":"2025-04-11T20:46:26.014087Z","iopub.status.idle":"2025-04-11T20:46:30.052018Z","shell.execute_reply.started":"2025-04-11T20:46:26.014062Z","shell.execute_reply":"2025-04-11T20:46:30.051108Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assign cluster labels from Agglomerative Clustering\n# Codesection generated by ChatGPT 4-Turbo\nfrom sklearn.cluster import AgglomerativeClustering\n\nagg = AgglomerativeClustering(n_clusters=3, linkage='ward')\nlabels_agg = agg.fit_predict(X_unsupervised)\n\n# Visualize clusters using PCA again\nplt.figure(figsize=(8,5))\nsns.scatterplot(x=X_pca[:,0], y=X_pca[:,1], hue=labels_agg, palette='Set1')\nplt.title(\"Hierarchical Clustering (PCA projection)\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-11T20:46:30.053046Z","iopub.execute_input":"2025-04-11T20:46:30.053928Z","iopub.status.idle":"2025-04-11T20:46:30.308570Z","shell.execute_reply.started":"2025-04-11T20:46:30.053898Z","shell.execute_reply":"2025-04-11T20:46:30.307602Z"}},"outputs":[],"execution_count":null}]}